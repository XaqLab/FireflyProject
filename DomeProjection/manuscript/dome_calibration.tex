% Template for PLoS
% Version 3.3 June 2016
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended 
% to minimize problems and delays during our production 
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % % 
%
% Once your paper is accepted for publication, 
% PLEASE REMOVE ALL TRACKED CHANGES in this file 
% and leave only the final text of your manuscript. 
% PLOS recommends the use of latexdiff to track changes during review, as this
% will help to maintain a clean tex file.  Visit
% https://www.ctan.org/pkg/latexdiff?lang=en for info or contact us at
% latex@plos.org.
%
%
% There are no restrictions on package use within the LaTeX files except that
% no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% The manuscript LaTeX source should be contained within a single file (do not
% use \input, \externaldocument, or similar commands).
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they
% are first cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file. 
% - Figures generated using LaTeX should be extracted and removed from the PDF
%   before submission. 
% - Figures containing multiple panels/subfigures must be combined into one
%   image file before submission.
% For figure citations, please use "Fig" instead of "Figure".  See
% http://journals.plos.org/plosone/s/figures for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - spacing/line breaks within cells to alter layout or alignment
% - do not nest tabular environments (no tabular environments within tabular
%   environments)
% - no graphics or colored text (cell background color/shading OK)
% See http://journals.plos.org/plosone/s/tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth
% environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT Below are a few tips to help format your equations and other
% special characters according to our specifications. For more tips to help
% reduce the possibility of formatting errors during conversion, please see our
% LaTeX guidelines at http://journals.plos.org/plosone/s/latex
%
% For inline equations, please be sure to include all portions of an equation
% in the math environment.  For example, x$^2$ is incorrect; this should be
% formatted as $x^2$ (or $\mathrm{x}^2$ if the romanized font is desired).
%
% Do not include text that is not math in the math environment. For example,
% CO2 should be written as CO\textsubscript{2} instead of CO$_2$.
%
% Please add line breaks to long display equations when possible in order to
% fit size of the column. 
%
% For inline equations, please do not include punctuation (commas, etc) within
% the math environment unless this is part of the equation.
%
% When adding superscript or subscripts outside of brackets/braces, please
% group using {}.  For example, change "[U(D,E,\gamma)]^2" to
% "{[U(D,E,\gamma)]}^2". 
%
% Do not use \cal for caligraphic font.  Instead, use \mathcal{}
%
% % % % % % % % % % % % % % % % % % % % % % % % 
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% Use Unicode characters when possible
\usepackage[utf8x]{inputenc}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% ligatures disabled
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}

% array package and thick rules for tables
\usepackage{array}

% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% Remove comment for double spacing
%\usepackage{setspace} 
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}

% Use the PLoS provided BiBTeX style
\bibliographystyle{plos2015}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% Leave date blank
\date{}

% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
\setlength{\headheight}{27.023pt}
\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\sf PLOS}

%% Include all macros below

\newcommand{\lorem}{{\bf LOREM}}
\newcommand{\ipsum}{{\bf IPSUM}}

%% END MACROS SECTION


\begin{document}
\vspace*{0.2in}

% Title must be 250 characters or less.
\begin{flushleft}
{\Large
\textbf\newline{Calibration of a Murine Virtual Reality System}
}
\newline
% Insert author names, affiliations and corresponding author email (do not
% include titles, positions, or degrees).
\\
James W. Bridgewater\textsuperscript{1,2},
Reuben H. Fan\textsuperscript{1},
Dora E. Angelaki\textsuperscript{1},
Xaq S. Pitkow\textsuperscript{1,2*}
\\
\bigskip
\textbf{1} Department of Neuroscience, Baylor College of Medicine, Houston, TX,
USA
\\
\textbf{2} Department of Electrical and Computer Engineering, Rice University,
Houston, TX, USA
\\
\bigskip

% Insert additional author notes using the symbols described below. Insert
% symbol callouts after author names as necessary.
% 
% Remove or comment out the author notes below if they aren't used.
%
% Primary Equal Contribution Note
%\Yinyang These authors contributed equally to this work.

% Additional Equal Contribution Note
% Also use this double-dagger symbol for special authorship notes, such as
% senior authorship.
%\ddag These authors also contributed equally to this work.

% Current address notes
%\textcurrency Current Address: Dept/Program/Center, Institution Name, City,
%State, Country % change symbol to "\textcurrency a" if more than one current
%address note \textcurrency b Insert second current address \textcurrency c
%Insert third current address

% Deceased author note
%\dag Deceased

% Group/Consortium Author Note
%\textpilcrow Membership list can be found in the Acknowledgments section.

% Use the asterisk to denote corresponding authorship and provide email address
% in note below.
* xaq@rice.edu

\end{flushleft}
% Please keep the abstract below 300 words
\section*{Abstract}
For a visual virtual reality system to be effective, the projected visual scene must engage the vast majority of the subject's visual field. 
This is challenging with rodents due to their exceptionally large visual coverage. Several research groups have successfully developed 
virtual reality systems capable of immersing rodents in a virtual visual world using a single projector and a single non-planar mirror to 
project images to a curved screen. A major challenge for implementing these systems is correcting the distortion of the visual stimulus. 
The ability to confidently evaluate and robustly minimize the errors in the display of visual stimuli is key to successfully utilizing a rodent 
virtual reality system. Here we detail a calibration technique that is relatively simple to reproduce that minimizes visual display errors for 
virtual reality system that utilize a partial sphere screen, partial sphere mirror, and a single projector.


% Please keep the Author Summary between 150 and 200 words
% Use first person. PLOS ONE authors please skip this step. 
% Author Summary not valid for PLOS ONE submissions.   
%\section*{Author Summary}

\linenumbers

% Use "Eq" instead of "Equation" for equation citations.
\section*{Introduction}
For decades, the study of rodent behavior has been performed using physical arenas and mazes \cite{Moser2008RodentSpaceRev}. 
Thus, the physical dimensions of the laboratory space dictated the extent of rodent exploration. With the rise of rodent virtual reality 
(VR) systems, the creation virtual spaces unbound by the physical lab space became possible. In addition, rodents can be sufficiently 
stabilized inside the VR systems to allow for stable neural recording using electrophysiological or imaging methods 
\cite{harvey2009intracellular, schmidt2013cellular, aronov2014engagement, keller2012sensorimotor, ayaz2013locomotion, saleem2013integration}. 
The combination of these methodologies has revealed novel insights to how neurons respond during active navigation 
\cite{harvey2009intracellular, schmidt2013cellular, aronov2014engagement, keller2012sensorimotor, ayaz2013locomotion, saleem2013integration}.

A major challenge in designing a virtual world for rodents is adequately engaging their visual system. The visual field of mice and rats covers nearly 
the entire half sphere above the horizon and a large portion of the half sphere below it \cite{hughes1977topography, wagor1980retinotopic, 
schuett2002mapping, wang2007area}. Current systems address this challenge with multiple visual displays \cite{keller2012sensorimotor,
 ayaz2013locomotion, saleem2013integration} or use non-planar mirrors to increase the visual field covered by a single projector 
\cite{harvey2009intracellular, schmidt2013cellular, aronov2014engagement}. The difficulty in using multiple displays is the presence of bezels. 
The use of multiple displays has, in some cases, resulted in behavior which suggests that the animal is navigating the real space occupied by 
the displays rather that the virtual space shown on them \cite{holscher2005rats}. An alternative method is to employ non-planar mirrors to 
increase the effective coverage of single projector \cite{harvey2009intracellular, schmidt2013cellular, aronov2014engagement}. 
The most well-known examples use custom mirrors and projection surface shapes that, while not prohibitive, adds a layer of complexity 
increasing the barrier of entry \cite{holscher2005rats, harvey2009intracellular}. Alternatively, one can use a simple spherical mirror and 
spherical dome, making VR construction more accessible \cite {schmidt2013cellular}. Ultimately, the challenge of using non-planar mirrors 
is correcting the distortion of the projected visual stimuli. Correcting of the image distortion, in principle, requires an image modification by 
solving a straight-forward 3-dimensional trigonometry problem based on known specifications of the projector, mirror, projection surface, 
and the observer’s location. While conceptually simple, in practice, correcting for the visual distortions from non-planar mirrors can be challenging.

To achieve the best results, the system measurements are ideally known to sub-millimeter accuracy. This is difficult to accomplish via measurement 
because some elements of the system, like the projector's focal point, are not directly observable. Thus, to overcome these issues and achieve a 
highly accurate reproduction of viewing directions in our rodent VR system, we have developed a technique that utilizes a 3D printed calibration 
device to project spots of light in 37 known viewing directions relative the location of the observer's head. By mapping projected points in the 
projector image to known viewing directions displayed by the 3D printed device, it is possible to find values of the virtual reality system's geometric 
parameters (see Methods for list of parameters) that produce accurate calculated viewing directions by minimizing the difference between the known 
and calculated viewing directions. Once the system’s geometric parameters are known, an image can be modified such that projection of the modified 
image in the virtual reality system produces the original image. We will describe this method in detail. 

\section*{Materials and Methods}


\subsection*{System Geometry}

\subsection*{Viewing Direction Calculation}

Figure \ref{fig:SysScheme} is a depiction of our model VR system. Our objective 
for the visual stimuli in this system is to cover ~ 270\textdegree{} horizontal field of view, from 135\textdegree{} left of center to 135\textdegree{} 
right of center, and a 90\textdegree{} vertical field of view, from 20\textdegree{} below horizontal to 70\textdegree{} above horizontal. 
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{SysScheme.pdf}
\caption{{\bf System schematic.}
In our schematic, the configuration is set to emphasize the flexibility we have in the positioning of the point-A relative to the mirror, projector, and dome. Point-A is the observer's head location. Point-D is the origin of the sphere the projection dome is cut from. Point-E represents a location on the inner surface of the projection dome. Point-M is defined as the center of the sphere the mirror is cut from and is used as the origin point for our entire system. Point-N is the location that light from focal point from the projector, defined as point-P, hits.}
\label{fig:SysScheme}
\end{figure}
Our model system uses a half sphere to display projected images and a quarter sphere mirror to reflect an image coming from a single 
projector Fig. \ref{fig:SysScheme}. The animal’s head position is represented as a small ball sitting on a Styrofoam ball that is floating on a cushion of air 
similar to other frictionless treadmill systems (REF). A three dimensional unit vector is used to represent the viewing direction from the animal 
(Fig. 1 point-A) to a point on the spherical screen (Fig. 1 point-E). Calculation of the viewing direction corresponding to a point in the projector image 
is performed in three steps as illustrated in Fig. \ref{fig:SysScheme}. The first step is to calculate the three dimensional Cartesian coordinates of point-N 
where light from a given point in the projector image strikes the mirror. This is accomplished by considering the triangle consisting of the point-M, point-P 
(the projector’s focal point), and point-N illustrated in Fig. 1 using the law of cosines. The second step is to find the coordinates of point-E by considering 
the triangle defined by point-N, point-D, and point-E. Step 3 is to use the triangle defined by point-A, point-E, and point-M to calculate the vector from
 point-A to point-E and normalize it to get a unit vector that represents the viewing direction corresponding to the given point in the projector's image. 
Note that in our method, we have chosen point-M to be the origin of the system.
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{FRUS.pdf}
\caption{{\bf Frustrum.}
The pixel position from the projected image are represented by the variables u and v. The resolution of our projector is 1280x720. The image spread (and height) and rise are related to the throw distance.}
\label{fig:FRUS}
\end{figure}
This calculation requires quantitative values for several geometric properties of this virtual reality system. Specifically the location of the projector's focal point, 
the aspect ratio of its image (Fig. \ref{fig:FRUS}), and an angle quantifying how much the image spreads out horizontally as it gets farther from the projector and 
a slope describing how far the image rises as it gets farther from the projector (Fig. \ref{fig:FRUS}). Also required are the radius of the spherical mirror, the radius 
of the hemispherical screen, the location of the screen's center and the location of the animal's head relative to the projector focal point, point-P (Fig. \ref{fig:SysScheme}). While 
many of these parameters can be theoretically measured or provided, obtaining a sufficiently accurate values for all of these parameters is challenging. 
Particularly challenging is that the focal point of the projector, the center of the hemispherical screen and the center of the spherical mirror (the origin of our 
chosen coordinate system) are not directly observable. We therefore developed the calibration method described in the next section to find values of these 
parameters which result in accurate calculated viewing directions.
\begin{eqnarray}
\label{eq:schemeP}
	\mathrm{P_Y} = \underbrace{H(Y_n) - H(Y_n|\mathbf{V}^{Y}_{n})}_{S_Y} +
                       \underbrace{H(Y_n|\mathbf{V}^{Y}_{n})-
                       H(Y_n|\mathbf{V}^{X,Y}_{n})}_{T_{X\rightarrow Y}},
\end{eqnarray}

(Description of equation above missing)

The aspect ratio of the image from the projector is provided by the manufacturer. Here we used a DepthQ projector (1280x720 resolution).  The image rise for our 
projector is estimated 15 percent of the image height at a given throw distance. The image height is found by dividing the throw distance by the factor 1.39 for the 
minimum magnification setting. The image width is computed from the aspect ratio setting (16:9). The quarter sphere mirror is a standard 18-inch diameter safety 
mirror. The dome projection surface was custom made was designed to have a radius of 70 cm. We leveled the projector and placed it at a distance such that at the 
minimum magnification of the projector, the image being displayed (before any correction) was qualitatively crisp. We then proceeded to perform our custom 
calibration process.

\subsection*{Calibration Process}
One of the keys to making an accurate image from the perspective of the observer is properly correcting for image distortion due to the use of a curved mirror to 
reflect the projected image. We have developed a method for image correction that is relatively simple to replicate. We use a 3D printed calibration device (Fig. \ref{fig:3Ddev}) 
that projects 37 spots of light in known directions, four rows of nine spots plus one spot straight overhead. Each row has 9 spots located at yaw angles of -120, -90, 
-60, -30, 0, 30, 60, 90, and 120 degrees where 0 degrees is straight ahead, negative angles refer to the left visual hemifield and positive angles refer to locations in 
the right visual hemifield. The four rows are at pitch angles of -15, 0, 30, and 60 degrees where negative angles referring to the lower visual field and positive angles 
the upper visual field. This calibration device is placed at the animal's head location inside the virtual reality system. The light source is a diffuse light provided by a 
simple flashlight without any casing to confine the light beams. The result is circles with a radius of approximately 1 visual degree (Fig. \ref{fig:Dots}). To calibrate 
our image, we projected green dots in grid-like fashion and allow those points fall onto the dome projection surface. We then manually move each dot in a pixel wise 
fashion until each dot falls into the proper corresponding spot projected by the calibration device. We then save the pixel location of each dot emanating from the 
projector. This file constitutes a mapping between 37 points in the projector image and 37 known viewing directions which can be used to find virtual reality system 
geometry parameter values which produce accurate viewing directions. These parameter values are found by minimizing the sum of the square L2 norms of the 
vectors which constitute the differences between the calculated and known viewing directions. The values we are particularly interested is are the y and z coordinates 
of the dome, animal, and projector. The x coordinate is assumed to be the same meaning that the center of the dome, animal, and projector image center all fall on the 
same plane. This is done through careful construction. 

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{3Dcaldev.pdf}
\caption{{\bf 3D printed calibration device.}
A. Rendering of the 3D device. B. 3D printed device without flashlight. C. 3D printed device with flashlight.}
\label{fig:3Ddev}
\end{figure}
\subsection*{Image Modification}

The result of the minimization routine provides us with the parameters necessary to perform a pixel wise mapping from the projector to the appropriate location on the dome. 
The relationship between these two is given by:

INSERT EQUATION 2.

This relationship permits the user to create an image in a program such as OpenGL and then warp the image such that once it is displayed on the dome after reflecting off 
the mirror, the displayed image appears undistorted to the observer. Figure 5 provides examples of corrected and uncorrected images and is described in the Results section. 


%% For figure citations, please use "Fig" instead of "Figure".
%Nulla mi mi, Fig~\ref{fig1} venenatis sed ipsum varius, volutpat euismod diam.
%
%% Place figure captions after the first paragraph in which they are cited.
%\begin{figure}[!h]
%\caption{{\bf Bold the figure title.}
%Figure caption text here, please use this space for the figure panel
%descriptions instead of using subfigure commands. A: Lorem ipsum dolor sit
%amet. B: Consectetur adipiscing elit.}
%\label{fig1}
%\end{figure}

% Results and Discussion can be combined.
\section*{Results}

\subsection*{Finding the geometric values}

An important step for our method is obtaining quantitative values for several geometric properties. As previously specified in the Materials and Methods, we are particularly 
interested in mirror radius, the dome radius, and the y and z position of the animal, dome, projector relative the mirror point-P (Fig. 1). Our dome was designed to be 
approximately 70 cm in radius which is the value our method provided. The mirror diameter is reported as 18 in, our algorithm provided one of 17.7 in (1.67 percent smaller 
than expected). We estimated the throw distance to be approximately 79.5 cm which would yield a rise position of approximately 8.57 cm. The final rise position determined 
by our algorithm was 8.4 cm (2.1 percent smaller). While none of these values are hugely inaccurate, the consistent difference does illustrate how difficult it is to find exact 
values. While having hand measurements of these values is not necessary, they are useful because they provide realistic constraints on our algorithm rather than do a full 
exhaustive search. 
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{Dots.pdf}
\caption{{\bf Calibration dots.}
The circles of light come from the 3D calibration device (see Fig. \ref{fig:3Ddev}). The green dots are the position after the Calibration process described in the Materials and Methods}
\label{fig:Dots}
\end{figure}
\subsection*{Image Modification}
Because we focus on only a few parameters of interest to simplify the procedure, there are a few areas where the resulting projecting could be improved. In Fig. \ref{fig:Dots}, the 
green dots are the final positions after the calibration has been applied. Note that the green dots are not perfectly centered. However the radius of each of the projected 
circles from the 3D calibration device is approximately 1 visual degree. Thus as long as the green dots fall within these circles they are very close to the ideal positions. The 
reasons why they do not fall into the ideal positions are in part due to the variables we do not allow to vary. We expand on this point in the Discussion.

\subsection*{Image display}

To illustrate the effectiveness of our method, we provide a set of corrected, non-corrected image, and native image in Fig. \ref{fig:Compare}. The corrected and non-corrected images 
were taken by a webcam inside the VR system from the perspective of a viewer. GET A SET AND DESCRIBE. 

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{original_projected.pdf}
\caption{{\bf Original and Projected images.}
A/B. Original images. C/D. Image captures from a webcam placed at the location of the observer's head after projecting them onto the spherical projection surface.}
\label{fig:Compare}
\end{figure}

\subsection*{Image Modification}
Also notable is that we are able to perform these correction in a situation where viewing distance of the observer is not the radius of the dome in all viewing directions. 
In our configuration, our observer is raised relative the plane that marks the displayable surface of our half sphere. Our algorithm places the animal 18.5 cm higher than 
this plane and produce good quality images to the human eye. This has the same desired effect that pitching the dome forward to provide some lower visual field coverage 
\cite{schmidt2013cellular} or constructing a toroidal screen to encompass the lower visual field \cite{holscher2005rats, harvey2009intracellular}. By raising the animal, we 
are able to provide 20+ degrees of the lower visual field without having to add any additional surface. 

% Place tables after the first paragraph in which they are cited.
%\begin{table}[!ht]
%\begin{adjustwidth}{-2.25in}{0in} % Comment out/remove adjustwidth environment if table fits in text column.
%\centering
%\caption{
%{\bf Table caption Nulla mi mi, venenatis sed ipsum varius, volutpat euismod diam.}}
%\begin{tabular}{|l+l|l|l|l|l|l|l|}
%\hline
%\multicolumn{4}{|l|}{\bf Heading1} & \multicolumn{4}{|l|}{\bf Heading2}\\ \thickhline
%$cell1 row1$ & cell2 row 1 & cell3 row 1 & cell4 row 1 & cell5 row 1 & cell6 row 1 & cell7 row 1 & cell8 row 1\\ \hline
%$cell1 row2$ & cell2 row 2 & cell3 row 2 & cell4 row 2 & cell5 row 2 & cell6 row 2 & cell7 row 2 & cell8 row 2\\ \hline
%$cell1 row3$ & cell2 row 3 & cell3 row 3 & cell4 row 3 & cell5 row 3 & cell6 row 3 & cell7 row 3 & cell8 row 3\\ \hline
%\end{tabular}
%\begin{flushleft} Table notes Phasellus venenatis, tortor nec vestibulum
%	mattis, massa tortor interdum felis, nec pellentesque metus tortor nec
%	nisl. Ut ornare mauris tellus, vel dapibus arcu suscipit sed.
%\end{flushleft}
%\label{table1}
%\end{adjustwidth}
%\end{table}


%PLOS does not support heading levels beyond the 3rd (no 4th level headings).
%\subsection*{\lorem\ and \ipsum\ Nunc blandit a tortor.}
%\subsubsection*{3rd Level Heading.} 
%
%\begin{enumerate}
%	\item{react}
%	\item{diffuse free particles}
%	\item{increment time by dt and go to 1}
%\end{enumerate}
%
%
%\subsection*{Sed ac quam id nisi malesuada congue.}
%
%
%\begin{itemize}
%	\item First bulleted item.
%	\item Second bulleted item.
%	\item Third bulleted item.
%\end{itemize}

\section*{Discussion}

Challenges
One of the challenges of our method, as presented, is that we assume the center of the observer’s head, the quarter sphere mirror, and the center of the 
projected image all fall onto a single plane. In practice, this is quite difficult to achieve. We used a plumb line and displayed a center line and manually moved the 
individual components until everything was bisected by the plumb line. In theory we add this to the variable that we search for. But increasing the number of 
variables we search for comes with its own concerns. The inclusion of a third position parameters for the dome, the projector, and the observer’s head increases 
the potential for local minima that have to be avoided. While this is not likely to be too computationally expensive, the addition of this parameter can make arriving 
at a values unreasonably difficult. Thus we chose the difficulties in manually aligning these centers to reduce the number of variables that need to be considered in 
our software. 

A second challenge is shadowing. In our configuration, the position of the animal and platform used to support the animal will casts a shadow preventing any images 
from being displayed. This is a design challenge that ideally falls within the 90 degree wedge behind the rodent’s head which is close to full horizontal visual field 
coverage (REF). This will be difficult depending on what materials are used to support the chosen rodent. For rats the support system necessary will cast a larger 
shadow than one for a mouse. However amount of shadow cast can be mitigated, but not avoided, with clever design of the supporting mechanism. Once the 
supporting mechanism is set, the amount of shadowing can be assessed.

A final challenge is more of a consideration when designing a system similar to that presented here. It is not advisable to attempt using a 9 in diameter quarter sphere 
mirror with our dome. Similarly, it is not advisable to use an 18 in diameter quarter sphere mirror with a dome of 35 cm radius. In the former, it would be difficult to find 
positions that would allow one to cover enough of the dome surface to achieve adequate visual field coverage. The latter would not have this issue but would present 
practical challenges given the size of the mirror relative to the size of the projection dome.  

Benefits
The main benefit of our method is that it allows for the user to optimize the visual scene for a large number of potential components and positions of the animal. 
While we have the space to house a large 70 cm radius half sphere. This might not be the case for all. However our method allows others to choose sizes that better 
fit the constraints of their lab and provides them with a method to correct for visual distortions. In addition, we could theoretically use less half of sphere and our method 
would still work. This flexibility of design is permissible because we allow for the observer to be in any position inside the dome. In our example we move the position of the 
observer’s head 18.5 cm above point-D (Fig. 1). This allows us to provide 20+ degrees of the lower visual field without needing to add additional projection space. Past 
examples have placed the viewer at point-D (see REF). The reason for this is similar to our aligning the observer’s head, the mirrors center, the dome’s center, and the
 projected image center. By centering the mouse and the deflecting mirror, several parameters are simplified. One of the parameters is the viewing distance to all points on 
the screen are defined by the radius of the dome. This would reduce the complexity of the distortion correction considerably. However the disadvantage of this is such a 
configuration necessarily sacrifices visual field coverage unless the dome is constructed in a fashion that extends the projection surface. Another tactic to gaining 
more visual field is to use cones or toroidal screens with custom mirrors \cite{holscher2005rats, harvey2009intracellular}, to use a cone shape \cite{aronov2014engagement}, 
or simple boxes \cite{aghajan2015impaired}. Regardless of the specifics components used to construct an 
immersive VR system, in the end, the problem still remains the same, how to calibrate the visual scene. By allowing for different geometric configurations providing parts of 
the lower visual field of locations behind the head are a simple matter of simply moving the observer into the dome a certain distance. Because we use simple components that 
are more widely accessible, our method should be more accessible by a wider array of experimenters. However should other shapes be used, our method is theoretically 
adjustable to fit a wider array of potential system designs.

\section*{Conclusion}

information, see \nameref{S1_Appendix}.

\section*{Supporting Information}

% Include only the SI item label in the paragraph heading. Use the \nameref{label} command to cite SI items in the text.
\paragraph*{S1 Fig.}
\label{S1_Fig}
{\bf Bold the title sentence.} Add descriptive text after the title of the item
(optional).

\paragraph*{S2 Fig.}
\label{S2_Fig}
{\bf Lorem Ipsum.} Maecenas convallis mauris sit amet sem ultrices gravida.
Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod
ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

\paragraph*{S1 File.}
\label{S1_File}
{\bf Lorem Ipsum.}  Maecenas convallis mauris sit amet sem ultrices gravida.
Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod
ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

\paragraph*{S1 Video.}
\label{S1_Video}
{\bf Lorem Ipsum.}  Maecenas convallis mauris sit amet sem ultrices gravida.
Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod
ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

\paragraph*{S1 Appendix.}
\label{S1_Appendix}
{\bf Lorem Ipsum.} Maecenas convallis mauris sit amet sem ultrices gravida.
Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod
ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

\paragraph*{S1 Table.}
\label{S1_Table}
{\bf Lorem Ipsum.} Maecenas convallis mauris sit amet sem ultrices gravida.
Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod
ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

\section*{Acknowledgments}

This work was supported by NSF IOS-1450923, the Simons Foundation, and the
McNair Foundation.

\nolinenumbers

% Either type in your references using
% \begin{thebibliography}{}
% \bibitem{}
% Text
% \end{thebibliography}
%
% or
%
% Compile your BiBTeX database using our plos2015.bst
% style file and paste the contents of your .bbl file
% here.
% 

\bibliography{bibliography}


\end{document}

